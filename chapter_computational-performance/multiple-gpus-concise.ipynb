{"cells": [{"cell_type": "code", "metadata": {}, "outputs": [], "source": ["!curl -O https://raw.githubusercontent.com/deepjavalibrary/d2l-java/master/tools/fix-colab-gpu.sh && bash fix-colab-gpu.sh"], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["## Prepare Java Kernel for Google Colab\n", "Since Java is not natively supported by Colab, we need to run the following code to enable Java kernel on Colab.\n", "\n", "1. Run the cell bellow (click it and press Shift+Enter),\n", "2. (If training on CPU, skip this step) If you want to use the GPU with MXNet in DJL 0.10.0, we need CUDA 10.1 or CUDA 10.2.\nSince Colab supports CUDA 10.1, we will have to follow some steps to setup the environment.\nRefresh the page (press F5) and stay at Python runtime on GPU. Run the file fix-colab-gpu script.\n\nAnd then ensure that you have switched to CUDA 10.1.\n3. After that, switch runtime to Java and hardware to GPU.(Might require refreshing the page and switching runtime)\n", "\n", "Now you can write Java code."]}, {"cell_type": "code", "metadata": {}, "outputs": [], "source": ["!curl -O https://raw.githubusercontent.com/deepjavalibrary/d2l-java/master/tools/colab_build.sh && bash colab_build.sh"], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["# \u591aGPU\u7684\u7b80\u6d01\u5b9e\u73b0\n", ":label:`sec_multi_gpu_concise`\n", "\n", "\u6bcf\u4e2a\u65b0\u6a21\u578b\u7684\u5e76\u884c\u8ba1\u7b97\u90fd\u4ece\u96f6\u5f00\u59cb\u5b9e\u73b0\u662f\u65e0\u8da3\u7684\u3002\u6b64\u5916\uff0c\u4f18\u5316\u540c\u6b65\u5de5\u5177\u4ee5\u83b7\u5f97\u9ad8\u6027\u80fd\u4e5f\u662f\u6709\u597d\u5904\u7684\u3002\u4e0b\u9762\u6211\u4eec\u5c06\u5c55\u793a\u5982\u4f55\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u7684\u9ad8\u7ea7API\u6765\u5b9e\u73b0\u8fd9\u4e00\u70b9\u3002\u6570\u5b66\u548c\u7b97\u6cd5\u4e0e :numref:`sec_multi_gpu`\u4e2d\u7684\u76f8\u540c\u3002\u4e0d\u51fa\u6240\u6599\uff0c\u4f60\u81f3\u5c11\u9700\u8981\u4e24\u4e2aGPU\u6765\u8fd0\u884c\u672c\u8282\u7684\u4ee3\u7801\u3002\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%load ../utils/djl-imports\n", "%load ../utils/plot-utils\n", "%load ../utils/Training.java"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import ai.djl.basicdataset.cv.classification.*;\n", "import ai.djl.metric.*;\n", "import org.apache.commons.lang3.ArrayUtils;"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \u7b80\u5355\u7f51\u7edc\n", "\n", "\u8ba9\u6211\u4eec\u4f7f\u7528\u4e00\u4e2a\u6bd4 :numref:`sec_multi_gpu`\u7684LeNet\u66f4\u6709\u610f\u4e49\u7684\u7f51\u7edc\uff0c\u5b83\u4f9d\u7136\u80fd\u591f\u5bb9\u6613\u5730\u548c\u5feb\u901f\u5730\u8bad\u7ec3\u3002\u6211\u4eec\u9009\u62e9\u7684\u662f :cite:`He.Zhang.Ren.ea.2016`\u4e2d\u7684ResNet-18\u3002\u56e0\u4e3a\u8f93\u5165\u7684\u56fe\u50cf\u5f88\u5c0f\uff0c\u6240\u4ee5\u7a0d\u5fae\u4fee\u6539\u4e86\u4e00\u4e0b\u3002\u4e0e :numref:`sec_resnet`\u7684\u533a\u522b\u5728\u4e8e\uff0c\u6211\u4eec\u5728\u5f00\u59cb\u65f6\u4f7f\u7528\u4e86\u66f4\u5c0f\u7684\u5377\u79ef\u6838\u3001\u6b65\u957f\u548c\u586b\u5145\uff0c\u800c\u4e14\u5220\u9664\u4e86\u6700\u5927\u6c47\u805a\u5c42\u3002\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Residual extends AbstractBlock {\n", "\n", "    private static final byte VERSION = 2;\n", "\n", "    public ParallelBlock block;\n", "\n", "    public Residual(int numChannels, boolean use1x1Conv, Shape strideShape) {\n", "        super(VERSION);\n", "\n", "        SequentialBlock b1;\n", "        SequentialBlock conv1x1;\n", "\n", "        b1 = new SequentialBlock();\n", "\n", "        b1.add(Conv2d.builder()\n", "                .setFilters(numChannels)\n", "                .setKernelShape(new Shape(3, 3))\n", "                .optPadding(new Shape(1, 1))\n", "                .optStride(strideShape)\n", "                .build())\n", "                .add(BatchNorm.builder().build())\n", "                .add(Activation::relu)\n", "                .add(Conv2d.builder()\n", "                        .setFilters(numChannels)\n", "                        .setKernelShape(new Shape(3, 3))\n", "                        .optPadding(new Shape(1, 1))\n", "                        .build())\n", "                .add(BatchNorm.builder().build());\n", "\n", "        if (use1x1Conv) {\n", "            conv1x1 = new SequentialBlock();\n", "            conv1x1.add(Conv2d.builder()\n", "                    .setFilters(numChannels)\n", "                    .setKernelShape(new Shape(1, 1))\n", "                    .optStride(strideShape)\n", "                    .build());\n", "        } else {\n", "            conv1x1 = new SequentialBlock();\n", "            conv1x1.add(Blocks.identityBlock());\n", "        }\n", "\n", "        block = addChildBlock(\"residualBlock\", new ParallelBlock(\n", "                list -> {\n", "                    NDList unit = list.get(0);\n", "                    NDList parallel = list.get(1);\n", "                    return new NDList(\n", "                            unit.singletonOrThrow()\n", "                                    .add(parallel.singletonOrThrow())\n", "                                    .getNDArrayInternal()\n", "                                    .relu());\n", "                },\n", "                Arrays.asList(b1, conv1x1)));\n", "    }\n", "\n", "    @Override\n", "    protected NDList forwardInternal(\n", "            ParameterStore parameterStore,\n", "            NDList inputs,\n", "            boolean training,\n", "            PairList<String, Object> params) {\n", "        return block.forward(parameterStore, inputs, training);\n", "    }\n", "\n", "    @Override\n", "    public Shape[] getOutputShapes(Shape[] inputs) {\n", "        Shape[] current = inputs;\n", "        for (Block block : block.getChildren().values()) {\n", "            current = block.getOutputShapes(current);\n", "        }\n", "        return current;\n", "    }\n", "\n", "    @Override\n", "    protected void initializeChildBlocks(NDManager manager, DataType dataType, Shape... inputShapes) {\n", "        block.initialize(manager, dataType, inputShapes);\n", "    }\n", "}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["public SequentialBlock resnetBlock(int numChannels, int numResiduals, boolean isFirstBlock) {\n", "\n", "        SequentialBlock blk = new SequentialBlock();\n", "        for (int i = 0; i < numResiduals; i++) {\n", "\n", "            if (i == 0 && !isFirstBlock) {\n", "                blk.add(new Residual(numChannels, true, new Shape(2, 2)));\n", "            } else {\n", "                blk.add(new Residual(numChannels, false, new Shape(1, 1)));\n", "            }\n", "        }\n", "        return blk;\n", "}\n", "\n", "int numClass = 10;\n", "// This model uses a smaller convolution kernel, stride, and padding and\n", "// removes the maximum pooling layer\n", "SequentialBlock net = new SequentialBlock();\n", "net\n", "    .add(\n", "            Conv2d.builder()\n", "                    .setFilters(64)\n", "                    .setKernelShape(new Shape(3, 3))\n", "                    .optPadding(new Shape(1, 1))\n", "                    .build())\n", "    .add(BatchNorm.builder().build())\n", "    .add(Activation::relu)\n", "    .add(resnetBlock(64, 2, true))\n", "    .add(resnetBlock(128, 2, false))\n", "    .add(resnetBlock(256, 2, false))\n", "    .add(resnetBlock(512, 2, false))\n", "    .add(Pool.globalAvgPool2dBlock())\n", "    .add(Linear.builder().setUnits(numClass).build());"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \u7f51\u7edc\u521d\u59cb\u5316\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["`setInitializer()`\u51fd\u6570\u5141\u8bb8\u6211\u4eec\u5728\u6240\u9009\u8bbe\u5907\u4e0a\u521d\u59cb\u5316\u53c2\u6570\u3002\u8bf7\u53c2\u9605 :numref:`sec_numerical_stability`\u590d\u4e60\u521d\u59cb\u5316\u65b9\u6cd5\u3002\u8fd9\u4e2a\u51fd\u6570\u5728\u591a\u4e2a\u8bbe\u5907\u4e0a\u521d\u59cb\u5316\u7f51\u7edc\u65f6\u7279\u522b\u65b9\u4fbf\u3002\u8ba9\u6211\u4eec\u5728\u5b9e\u8df5\u4e2d\u8bd5\u4e00\u8bd5\u5b83\u7684\u8fd0\u4f5c\u65b9\u5f0f\u3002\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Model model = Model.newInstance(\"training-multiple-gpus-1\");\n", "model.setBlock(net);\n", "\n", "Loss loss = Loss.softmaxCrossEntropyLoss();\n", "\n", "Tracker lrt = Tracker.fixed(0.1f);\n", "Optimizer sgd = Optimizer.sgd().setLearningRateTracker(lrt).build();\n", "\n", "DefaultTrainingConfig config = new DefaultTrainingConfig(loss)\n", "        .optOptimizer(sgd) // Optimizer (loss function)\n", "        .optInitializer(new NormalInitializer(0.01f), Parameter.Type.WEIGHT) // setting the initializer\n", "        .optDevices(Engine.getInstance().getDevices(1)) // setting the number of GPUs needed\n", "        .addEvaluator(new Accuracy()) // Model Accuracy\n", "        .addTrainingListeners(TrainingListener.Defaults.logging()); // Logging\n", "\n", "Trainer trainer = model.newTrainer(config);"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u4f7f\u7528 :numref:`sec_multi_gpu`\u4e2d\u5f15\u5165\u7684`split()`\u51fd\u6570\u53ef\u4ee5\u5207\u5206\u4e00\u4e2a\u5c0f\u6279\u91cf\u6570\u636e\uff0c\u5e76\u5c06\u5207\u5206\u540e\u7684\u5206\u5757\u6570\u636e\u590d\u5236\u5230\u591a\u4e2a\u8bbe\u5907\u8bbe\u5907\u4e2d\u3002\u7f51\u7edc\u5b9e\u4f8b\u81ea\u52a8\u4f7f\u7528\u9002\u5f53\u7684GPU\u6765\u8ba1\u7b97\u524d\u5411\u4f20\u64ad\u7684\u503c\u3002\u6211\u4eec\u5c06\u5728\u4e0b\u9762\u751f\u6210$4$\u4e2a\u89c2\u6d4b\u503c\uff0c\u5e76\u5728GPU\u4e0a\u5c06\u5b83\u4eec\u62c6\u5206\u3002\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["NDManager manager = NDManager.newBaseManager();\n", "NDArray X = manager.randomUniform(0f, 1.0f, new Shape(4, 1, 28, 28));\n", "trainer.initialize(X.getShape());\n", "\n", "NDList[] res = Batchifier.STACK.split(new NDList(X), 4, true);\n", "\n", "ParameterStore parameterStore = new ParameterStore(manager, true);\n", "\n", "System.out.println(net.forward(parameterStore, new NDList(res[0]), false).singletonOrThrow());\n", "System.out.println(net.forward(parameterStore, new NDList(res[1]), false).singletonOrThrow());\n", "System.out.println(net.forward(parameterStore, new NDList(res[2]), false).singletonOrThrow());\n", "System.out.println(net.forward(parameterStore, new NDList(res[3]), false).singletonOrThrow());"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u4e00\u65e6\u6570\u636e\u901a\u8fc7\u7f51\u7edc\uff0c\u7f51\u7edc\u5bf9\u5e94\u7684\u53c2\u6570\u5c31\u4f1a\u5728*\u6709\u6570\u636e\u901a\u8fc7\u7684\u8bbe\u5907\u4e0a\u521d\u59cb\u5316*\u3002\u8fd9\u610f\u5473\u7740\u521d\u59cb\u5316\u662f\u57fa\u4e8e\u6bcf\u4e2a\u8bbe\u5907\u8fdb\u884c\u7684\u3002\u7531\u4e8e\u6211\u4eec\u9009\u62e9\u7684\u662fGPU0\u548cGPU1\uff0c\u6240\u4ee5\u7f51\u7edc\u53ea\u5728\u8fd9\u4e24\u4e2aGPU\u4e0a\u521d\u59cb\u5316\uff0c\u800c\u4e0d\u662f\u5728CPU\u4e0a\u521d\u59cb\u5316\u3002\u4e8b\u5b9e\u4e0a\uff0cCPU\u4e0a\u751a\u81f3\u6ca1\u6709\u8fd9\u4e9b\u53c2\u6570\u3002\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u6253\u5370\u53c2\u6570\u548c\u89c2\u5bdf\u53ef\u80fd\u51fa\u73b0\u7684\u4efb\u4f55\u9519\u8bef\u6765\u9a8c\u8bc1\u8fd9\u4e00\u70b9\u3002\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["net.getChildren().values().get(0).getParameters().get(\"weight\").getArray().get(new NDIndex(\"0:1\"));"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \u8bad\u7ec3\n", "\n", "\u5982\u524d\u6240\u8ff0\uff0c\u7528\u4e8e\u8bad\u7ec3\u7684\u4ee3\u7801\u9700\u8981\u6267\u884c\u51e0\u4e2a\u57fa\u672c\u529f\u80fd\u624d\u80fd\u5b9e\u73b0\u9ad8\u6548\u5e76\u884c\uff1a\n", "\n", "* \u9700\u8981\u5728\u6240\u6709\u8bbe\u5907\u4e0a\u521d\u59cb\u5316\u7f51\u7edc\u53c2\u6570\u3002\n", "* \u5728\u6570\u636e\u96c6\u4e0a\u8fed\u4ee3\u65f6\uff0c\u8981\u5c06\u5c0f\u6279\u91cf\u6570\u636e\u5206\u914d\u5230\u6240\u6709\u8bbe\u5907\u4e0a\u3002\n", "* \u8de8\u8bbe\u5907\u5e76\u884c\u8ba1\u7b97\u635f\u5931\u53ca\u5176\u68af\u5ea6\u3002\n", "* \u805a\u5408\u68af\u5ea6\uff0c\u5e76\u76f8\u5e94\u5730\u66f4\u65b0\u53c2\u6570\u3002\n", "\n", "\u6700\u540e\uff0c\u5e76\u884c\u5730\u8ba1\u7b97\u7cbe\u786e\u5ea6\u548c\u53d1\u5e03\u7f51\u7edc\u7684\u6700\u7ec8\u6027\u80fd\u3002\u9664\u4e86\u9700\u8981\u62c6\u5206\u548c\u805a\u5408\u6570\u636e\u5916\uff0c\u8bad\u7ec3\u4ee3\u7801\u4e0e\u524d\u51e0\u7ae0\u7684\u5b9e\u73b0\u975e\u5e38\u76f8\u4f3c\u3002\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["int numEpochs = Integer.getInteger(\"MAX_EPOCH\", 10);\n", "\n", "double[] testAccuracy;\n", "double[] epochCount;\n", "\n", "epochCount = new double[numEpochs];\n", "\n", "for (int i = 0; i < epochCount.length; i++) {\n", "    epochCount[i] = (i + 1);\n", "}\n", "\n", "Map<String, double[]> evaluatorMetrics = new HashMap<>();\n", "double avgTrainTimePerEpoch = 0;"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["public void train(int numEpochs, Trainer trainer, int batchSize) throws IOException, TranslateException {\n", "\n", "    FashionMnist trainIter = FashionMnist.builder()\n", "            .optUsage(Dataset.Usage.TRAIN)\n", "            .setSampling(batchSize, true)\n", "            .optLimit(Long.getLong(\"DATASET_LIMIT\", Long.MAX_VALUE))\n", "            .build();\n", "    FashionMnist testIter = FashionMnist.builder()\n", "            .optUsage(Dataset.Usage.TEST)\n", "            .setSampling(batchSize, true)\n", "            .optLimit(Long.getLong(\"DATASET_LIMIT\", Long.MAX_VALUE))\n", "            .build();\n", "\n", "    trainIter.prepare();\n", "    testIter.prepare();\n", "\n", "    Map<String, double[]> evaluatorMetrics = new HashMap<>();\n", "    double avgTrainTime = 0;\n", "\n", "    trainer.setMetrics(new Metrics());\n", "\n", "    EasyTrain.fit(trainer, numEpochs, trainIter, testIter);\n", "\n", "    Metrics metrics = trainer.getMetrics();\n", "\n", "    trainer.getEvaluators().stream()\n", "            .forEach(evaluator -> {\n", "                evaluatorMetrics.put(\"validate_epoch_\" + evaluator.getName(), metrics.getMetric(\"validate_epoch_\" + evaluator.getName()).stream()\n", "                        .mapToDouble(x -> x.getValue().doubleValue()).toArray());\n", "            });\n", "\n", "    avgTrainTime = metrics.mean(\"epoch\");\n", "    testAccuracy = evaluatorMetrics.get(\"validate_epoch_Accuracy\");\n", "    System.out.printf(\"test acc %.2f\\n\" , testAccuracy[numEpochs-1]);\n", "    System.out.println(avgTrainTime / Math.pow(10, 9) + \" sec/epoch \\n\");\n", "}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \u5b9e\u8df5\n", "\n", "\u8ba9\u6211\u4eec\u770b\u770b\u8fd9\u5728\u5b9e\u8df5\u4e2d\u662f\u5982\u4f55\u8fd0\u4f5c\u7684\u3002\u6211\u4eec\u5148\u5728\u5355\u4e2aGPU\u4e0a\u8bad\u7ec3\u7f51\u7edc\u8fdb\u884c\u9884\u70ed\u3002\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Table data = null;\n", "// We will check if we have at least 1 GPU available. If yes, we run the training on 1 GPU.\n", "if (Engine.getInstance().getGpuCount() >= 1) {\n", "    train(numEpochs, trainer, 256);\n", "\n", "    data = Table.create(\"Data\");\n", "    data = data.addColumns(\n", "            DoubleColumn.create(\"X\", epochCount), \n", "            DoubleColumn.create(\"testAccuracy\", testAccuracy)\n", "    );\n", "}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["// \u4ee5\u4e0b\u4ee3\u7801\u9700\u8981\u4f60\u6709\u81f3\u5c11\u4e00\u4e2aGPU\u8bbe\u5907\n", "// render(LinePlot.create(\"\", data, \"x\", \"testAccuracy\"), \"text/html\");    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["![Contour Gradient Descent.](https://d2l-java-resources.s3.amazonaws.com/img/training-with-1-gpu.png)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Table data = Table.create(\"Data\");\n", "\n", "// We will check if we have more than 1 GPU available. If yes, we run the training on 2 GPU.\n", "if (Engine.getInstance().getGpuCount() > 1) {\n", "\n", "    X = manager.randomUniform(0f, 1.0f, new Shape(1, 1, 28, 28));\n", "\n", "    Model model = Model.newInstance(\"training-multiple-gpus-2\");\n", "    model.setBlock(net);\n", "\n", "    loss = Loss.softmaxCrossEntropyLoss();\n", "\n", "    Tracker lrt = Tracker.fixed(0.2f);\n", "    Optimizer sgd = Optimizer.sgd().setLearningRateTracker(lrt).build();\n", "\n", "    DefaultTrainingConfig config = new DefaultTrainingConfig(loss)\n", "                .optOptimizer(sgd) // Optimizer (loss function)\n", "                .optInitializer(new NormalInitializer(0.01f), Parameter.Type.WEIGHT) // setting the initializer\n", "                .optDevices(Engine.getInstance().getDevices(2)) // setting the number of GPUs needed\n", "                .addEvaluator(new Accuracy()) // Model Accuracy\n", "                .addTrainingListeners(TrainingListener.Defaults.logging()); // Logging\n", "\n", "    Trainer trainer = model.newTrainer(config);\n", "    \n", "    trainer.initialize(X.getShape());\n", "\n", "    Map<String, double[]> evaluatorMetrics = new HashMap<>();\n", "    double avgTrainTimePerEpoch = 0;\n", "\n", "    train(numEpochs, trainer, 512);\n", "    \n", "    data = data.addColumns(\n", "        DoubleColumn.create(\"X\", epochCount), \n", "        DoubleColumn.create(\"testAccuracy\", testAccuracy)\n", "    );\n", "}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["// \u4ee5\u4e0b\u4ee3\u7801\u9700\u8981\u4f60\u6709\u4e24\u4e2a\u4ee5\u4e0aGPU\u8bbe\u5907\n", "// render(LinePlot.create(\"\", data, \"x\", \"testAccuracy\"), \"text/html\");"]}, {"cell_type": "markdown", "metadata": {}, "source": ["![Contour Gradient Descent.](https://d2l-java-resources.s3.amazonaws.com/img/training-with-2-gpu.png)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \u5c0f\u7ed3\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["* Gluon\u901a\u8fc7\u63d0\u4f9b\u4e00\u4e2a\u4e0a\u4e0b\u6587\u5217\u8868\uff0c\u4e3a\u8de8\u591a\u4e2a\u8bbe\u5907\u7684\u6a21\u578b\u521d\u59cb\u5316\u63d0\u4f9b\u539f\u8bed\u3002\n", "* \u795e\u7ecf\u7f51\u7edc\u53ef\u4ee5\u5728\uff08\u53ef\u627e\u5230\u6570\u636e\u7684\uff09\u5355GPU\u4e0a\u8fdb\u884c\u81ea\u52a8\u8bc4\u4f30\u3002\n", "* \u6bcf\u53f0\u8bbe\u5907\u4e0a\u7684\u7f51\u7edc\u9700\u8981\u5148\u521d\u59cb\u5316\uff0c\u7136\u540e\u518d\u5c1d\u8bd5\u8bbf\u95ee\u8be5\u8bbe\u5907\u4e0a\u7684\u53c2\u6570\uff0c\u5426\u5219\u4f1a\u9047\u5230\u9519\u8bef\u3002\n", "* \u4f18\u5316\u7b97\u6cd5\u5728\u591a\u4e2aGPU\u4e0a\u81ea\u52a8\u805a\u5408\u3002\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \u7ec3\u4e60\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["1. \u672c\u8282\u4f7f\u7528ResNet-18\uff0c\u8bf7\u5c1d\u8bd5\u4e0d\u540c\u7684\u8fed\u4ee3\u5468\u671f\u6570\u3001\u6279\u91cf\u5927\u5c0f\u548c\u5b66\u4e60\u7387\uff0c\u4ee5\u53ca\u4f7f\u7528\u66f4\u591a\u7684GPU\u8fdb\u884c\u8ba1\u7b97\u3002\u5982\u679c\u4f7f\u7528$8$\u4e2aGPU\uff08\u4f8b\u5982\uff0c\u5728AWS p2.16xlarge\u5b9e\u4f8b\u4e0a\uff09\u5c1d\u8bd5\u6b64\u64cd\u4f5c\uff0c\u4f1a\u53d1\u751f\u4ec0\u4e48\uff1f\n", "1. \u6709\u65f6\u5019\u4e0d\u540c\u7684\u8bbe\u5907\u63d0\u4f9b\u4e86\u4e0d\u540c\u7684\u8ba1\u7b97\u80fd\u529b\uff0c\u6211\u4eec\u53ef\u4ee5\u540c\u65f6\u4f7f\u7528GPU\u548cCPU\uff0c\u90a3\u5e94\u8be5\u5982\u4f55\u5206\u914d\u5de5\u4f5c\uff1f\u4e3a\u4ec0\u4e48\uff1f\n", "\n"]}], "metadata": {"kernelspec": {"display_name": "Java", "language": "java", "name": "java"}, "language_info": {"codemirror_mode": "java", "file_extension": ".jshell", "mimetype": "text/x-java-source", "name": "Java", "pygments_lexer": "java", "version": "14.0.2+12"}}, "nbformat": 4, "nbformat_minor": 4}